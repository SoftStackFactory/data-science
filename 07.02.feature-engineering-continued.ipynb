{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07.02.feature-engineering-continued.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"jzR1Lxui_ujm","colab_type":"text"},"source":["# More Information About Categorical Data Feature Engineering:\n","\n","We've stated before many machine learning algorithms cannot work with categorical data directly. The categories must be converted into numbers. This is required for both input and output variables that are categorical.\n","\n","We will discuss the different ways we can do this below.\n","\n","The key thing to remember is that we want to help this machine learning model learn as many unique traits and characteristics of the dataset as possible without the loss of information when we convert (encode) the categorical values to numerical values.\n","\n","## Different Types Of Categorical Data:\n","There are two different types of categorical data and it is important to understand the difference before we discuss how to convert these categorical features to numbers.\n","\n","<br> \n","\n","### `Nominal` Categorical Data \n","Nominal scales are used for labeling variables, without any quantitative value.  “Nominal” scales could simply be called “labels.”  None of these values have any numerical significance. \n","\n","**i.e.**\n","\n","Whats your hair color?\n","- `1- Brown`\n","- `2- Black`\n","- `3- Blonde`\n","- `4- Grey`\n","- `5- Other`\n","\n","Note: These are strings (text) not numbers\n","\n","All of these values do not have any numerical significance. Unlike `Ordinal` Categorical Data.\n","\n","<br>\n","\n","### `Ordinal` Categorical Data\n","With ordinal scales, the order of the values is what’s important and significant, but the differences between each one is not really known.\n","\n","**i.e.**\n","\n","How do you feel today?\n","- `1. Very Happy`\n","- `2. Happy`\n","- `3. Ok`\n","- `4. Unhappy`\n","- `5. Very Unhappy`\n","\n","Note: These are strings (text) not numbers\n","\n","or \n","\n","What size shirt do you wear?\n","- `1. Extra Small`\n","- `2. Small`\n","- `3. Medium`\n","- `4. Large`\n","- `5. Extra Large `\n","\n","Note: These are strings (text) not numbers\n","\n","Through your experience you can agree that:\n","```Extra Small < Small < Medium < Large < Extra Large```\n","\n","Unlike `nominal` categorical data, you might be able to see that there is a significance of order in `ordinal` categorical data.\n","\n","In each case, we can confirm that there is an order in the different unique values. You can compare the unique values to each other to represent more semantic meaning. Although you can say that `Extra Small` is less than `Small` and `Large` is less than `Extra Large`, you cannot really measure the difference between the two comparisons. For example if we say that the difference in size between `Extra Small` and `Small` is `15%` we cannot assume that the difference in `Large` and `Extra Large` is the same. The difference in size of `Large` and `Extra Large` could possiblly be `10%`. Here is another example, we do not understand if the difference between “OK” and “Unhappy” is the same as the difference between “Very Happy” and “Happy”,  We just can’t say.\n","\n","Ordinal scales are typically measures of non-numeric concepts like satisfaction, happiness, discomfort, etc.\n","\n","**Advanced note:** The best way to determine central tendency on a set of ordinal data is to use the mode or median; a purist will tell you that the mean cannot be defined from an ordinal set.\n","\n","[Reference for different types of categorical data](https://www.mymarketresearchmethods.com/types-of-data-nominal-ordinal-interval-ratio/)\n","\n","<hr>\n","\n","## Converting Categorical Data \n","\n","Now that we understand the difference between `nomianal` and `ordinal` categorical data we can discuss how to convert these text values to numeric values.\n","\n","### Converting `nominal` data:\n","\n","For `nominal` data we will perform `one hot encoding`. `One-hot encoding` is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction, it allows the representation of categorical data to be more expressive.\n","\n","`One-hot encoding` converts a specific column of unique values to multiple columns. Each new column would pertain to  single unique value in the original column. The values in the new column are boolean values, where 1 signifies that it is that value and 0 signifiying that it is not that value.\n","\n","For example:"]},{"cell_type":"code","metadata":{"id":"0N5pxGPrnYZ6","colab_type":"code","outputId":"c0463b94-95c0-4b3e-f3ef-dc1d07a92ed2","executionInfo":{"status":"ok","timestamp":1572977938532,"user_tz":480,"elapsed":647,"user":{"displayName":"Matt Hess","photoUrl":"","userId":"00800340733434721825"}},"colab":{"base_uri":"https://localhost:8080/","height":266}},"source":["import pandas as pd\n","data = {'hair color': ['Black', 'Black', 'Blonde', 'Brown', 'Grey', 'Grey', 'Other']}\n","df = pd.DataFrame(data)\n","display(df)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hair color</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Black</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Black</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Blonde</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Brown</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Grey</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Grey</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  hair color\n","0      Black\n","1      Black\n","2     Blonde\n","3      Brown\n","4       Grey\n","5       Grey\n","6      Other"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"qfNtoslOog7i","colab_type":"text"},"source":["After performing `one-hot encoding`:"]},{"cell_type":"code","metadata":{"id":"zp8oWn36oHO9","colab_type":"code","outputId":"1e8d7fe9-5da8-4595-ac0e-b9b1adf43f3d","executionInfo":{"status":"ok","timestamp":1572977940026,"user_tz":480,"elapsed":489,"user":{"displayName":"Matt Hess","photoUrl":"","userId":"00800340733434721825"}},"colab":{"base_uri":"https://localhost:8080/","height":266}},"source":["pd.get_dummies(df)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>hair color_Black</th>\n","      <th>hair color_Blonde</th>\n","      <th>hair color_Brown</th>\n","      <th>hair color_Grey</th>\n","      <th>hair color_Other</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   hair color_Black  hair color_Blonde  ...  hair color_Grey  hair color_Other\n","0                 1                  0  ...                0                 0\n","1                 1                  0  ...                0                 0\n","2                 0                  1  ...                0                 0\n","3                 0                  0  ...                0                 0\n","4                 0                  0  ...                1                 0\n","5                 0                  0  ...                1                 0\n","6                 0                  0  ...                0                 1\n","\n","[7 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"cBDpQE9-mulo","colab_type":"text"},"source":["These binary variables are often called “dummy variables” in other fields, such as statistics.\n","\n","The one thing to note about `one-hot encoding` is the `curse of dimensionality`. If a column has an excessive amount of unique values it could hurt certain machine learning algorithms to perform `one-hot encoding`. In this case try your best to group unique values together through educated and domain knowledge.\n","\n","Using this encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (predictions halfway between categories).\n","\n","### Converting `ordinal` data:\n","\n","For `ordinal` categorical data we will perform a different type of encoding. `Ordinal encoding` is done to ensure encoding of variable retains ordinal nature of the variable. In short we convert the categorical values to numerical values through a more controlled and defined way of mapping these values from categorical to numeric values, rather than letting the computer randomly convert the values. Once we do convert these values we will not `one-hot encode`, rather we will leave the numeric values in one column opposed to transforming the column into multiple columns.\n","\n","\"Treating ordered categorical data as a numerical variables preserves the information contained in the ordering that woud be lost if it were transformed using `one-hot encoding`\" -O'reilly, Practical Statistics For Data Science.\n","\n","We can convert these through the following way: "]},{"cell_type":"code","metadata":{"id":"DLksUMnIyEL6","colab_type":"code","outputId":"59c34967-2773-406e-cefc-7c00c7ee19c7","executionInfo":{"status":"ok","timestamp":1572978235697,"user_tz":480,"elapsed":522,"user":{"displayName":"Matt Hess","photoUrl":"","userId":"00800340733434721825"}},"colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["data = {'shirt size': ['XS', 'XS', 'S',  'M', 'M', 'L', 'XL', 'XL']}\n","df = pd.DataFrame(data)\n","display(df)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>shirt size</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>XS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>XS</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>M</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>L</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>XL</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>XL</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  shirt size\n","0         XS\n","1         XS\n","2          S\n","3          M\n","4          M\n","5          L\n","6         XL\n","7         XL"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"AJIkcOmhy_fz","colab_type":"text"},"source":["After `ordinal encoding`:"]},{"cell_type":"code","metadata":{"id":"-8NzfKJEzEq6","colab_type":"code","outputId":"169b0cf3-3583-424f-e599-a294a8cca160","executionInfo":{"status":"ok","timestamp":1572978237492,"user_tz":480,"elapsed":468,"user":{"displayName":"Matt Hess","photoUrl":"","userId":"00800340733434721825"}},"colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["size_dict = {\n","    'XS':1,\n","    'S':2,\n","    'M':3,\n","    'L':4,\n","    'XL':5\n","    }\n","\n","df['shirt size ordinal'] = df['shirt size'].map(size_dict)\n","display(df)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>shirt size</th>\n","      <th>shirt size ordinal</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>XS</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>XS</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>S</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>M</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>M</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>L</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>XL</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>XL</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  shirt size  shirt size ordinal\n","0         XS                   1\n","1         XS                   1\n","2          S                   2\n","3          M                   3\n","4          M                   3\n","5          L                   4\n","6         XL                   5\n","7         XL                   5"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"6G5SK0QFz3Dl","colab_type":"text"},"source":["### Converting Categorical Data Recap: \n","- If a column has an excessive amount of unique values it could hurt certain machine learning algorithms to perform one-hot encoding.\n","- \"Treating ordered categorical data as a numerical variables preserves the information contained in the ordering that woud be lost if it were transformed using one-hot encoding\" -O'reilly, Practical Statistics For Data Science.\n","\n","Check out this link if you are curious about the [pros and cons of treating ordinal values as numerical values rather than one-hot encoding](https://www.theanalysisfactor.com/pros-and-cons-of-treating-ordinal-variables-as-nominal-or-continuous/)\n","\n","<br>\n","\n","## **Of course we will have to create a model with the different ways of encoding to see which performs better for the specific data set, remember it's an iterative process and there is no one answer fits all, all datasets and models have their own way of performing better.**\n","\n","<br>\n","\n","Actually there are many way ways to encode categorical data, check out the following links for more information:\n","\n","[Categorical Encoding Reference](https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02)\n"]},{"cell_type":"markdown","metadata":{"id":"gcPExR_o6rJq","colab_type":"text"},"source":["<hr>\n","\n","<br>\n","\n","## Numerical Data Feature Engineering\n","\n","### `Discretization`\n","Discretization (otherwise known as quantization or binning) provides a way to partition continuous features into discrete values. Certain datasets with continuous features may benefit from discretization, because discretization can transform the dataset of continuous attributes to one with only nominal attributes, or in other words convert a column to have less unique values.\n","\n","More technically `discretization` is the process of transferring continuous functions, models, variables, and equations into discrete counterparts or partitions.\n","\n","In a sense to help the model potentially perform better we will convert continuous data points to discrete data points.\n","\n","\"Discretized features can make a model more expressive, while maintaining interpretability. For instance, pre-processing with a discretizer can introduce nonlinearity to linear models.\" -[scikit-learn.org](https://scikit-learn.org/stable/modules/preprocessing.html#discretization)\n","\n","\n","#### Sklearn's preprocessing K-bins discretization\n","We will use sklearn's preprocessing `KBinsDiscretizer` function to  discretizes features into k bins:\n","\n","#### Sklearn's KBinsDiscretizer() parameters:\n","- `n_bins`(int or array-like), The number of bins to produce for each column.  **Note:** Raises ValueError if n_bins < 2.\n","- `encode` ({‘onehot’, ‘onehot-dense’, ‘ordinal’}): Method used to encode the transformed result. if set to `ordinal` return the bin identifier encoded as an integer value.\n","\n","We will call `fit()` on the KBinsDiscretizer method to fit the estimator. This will essentially find out the different ranges for each bin."]},{"cell_type":"code","metadata":{"id":"K4GkfP4n7DaN","colab_type":"code","colab":{}},"source":["from sklearn import preprocessing\n","import numpy as np\n","X = np.array([[ -3., 5., 15 ],\n","              [  0., 6., 14 ],\n","              [  6., 3., 11 ]])\n","\n","est = preprocessing.KBinsDiscretizer(n_bins=[3, 2, 2], encode='ordinal').fit(X)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jksbkeap7CJ8","colab_type":"text"},"source":["\n","By default the output is one-hot encoded into a sparse matrix ([See Encoding categorical features](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features)) and this can be configured with the encode parameter.\n","\n","For each feature, the bin edges are computed during fit and together with the number of bins, they will define the intervals. Therefore, for the current example, these intervals are defined as:\n","\n","**Key:** \n","- `[` and `]` are inclusive\n","- `(` and `)` are exclusive\n","\n","feature 1: ```[-infinity, -1), [-1,2), [2,infinity)```\n","\n","feature 2: ```[-infinity, 5), [5,infinity)```\n","\n","feature 3: ```[-infinity, 14), [14, infinity)```\n","\n","<br>\n","\n","We will call `.transform()` on the estimator to transform the data to the desired output, discretization of continuous numerical values to discrete numerical values.\n","\n","Based on these bin intervals, X is transformed as follows:\n","\n","\n","                 \n"]},{"cell_type":"code","metadata":{"id":"CTWUI0bdvMOq","colab_type":"code","outputId":"2b296d87-264d-476f-af11-67bf89fb62f7","executionInfo":{"status":"ok","timestamp":1572980512962,"user_tz":480,"elapsed":483,"user":{"displayName":"Matt Hess","photoUrl":"","userId":"00800340733434721825"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["est.transform(X)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 1., 1.],\n","       [1., 1., 1.],\n","       [2., 0., 0.]])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"xniBnYN98UuX","colab_type":"text"},"source":["Refer here for the documentation:\n","- [discretization sci-kit learn documentation](https://scikit-learn.org/stable/modules/preprocessing.html#discretization)"]},{"cell_type":"markdown","metadata":{"id":"ZwMCAYFd82nZ","colab_type":"text"},"source":["## **Of course we will have to create a model with performing discretization and also without performing discretization to see which performs better for the specific data set, remember it's an iterative process and there is no one answer fits all, all datasets and models have their own way of performing better.**"]}]}