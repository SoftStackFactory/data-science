{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08.01.eda-data-cleaning-feature-engineering-midterm.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Es-ceD1D3ytV"},"source":["<hr>\n","\n","##### Mount Drive - **Google Colab Only Step**\n","\n","When using google colab in order to access files on our google drive we need to mount the drive by running the below python cell, then clicking the link it generates and pasting the code in the cell.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YKHWrhnJ3ytR","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"x5AzSk7g3ytO"},"source":["Change Directory To Access The Dependent Files - **Google Colab Only Step**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j9rgWUe03ytL","colab":{}},"source":["directory = \"student\"\n","if (directory == \"student\"):\n","  %cd drive/Colab\\ Notebooks/data-science-track/\n","else:\n","  %cd drive/Shared\\ drives/Rubrik/Data\\ Science/Course/Data-Science-Track"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zOm9NR3-mm-5","colab_type":"text"},"source":["# Midterm Project\n","\n","Overall goal of this is to create a useful dataset so that we can create a machine learning model to be able to predict the `tx_price` variable based on unique features. \n","\n","<br>\n","\n","It is important to note that having more features (columns/series) and unique values for each feature doesn't mean a better machine learning algorithm. Infact it will increase the noise and decrease the efficiency and can result in overfitting.\n","\n","<br>\n","\n","A **target variable** is the variable whose values are to be modeled and predicted by other variables (features). Those variables (features), called “predictor variables” are variables whose values will be used to predict the value of the target variable.\n","\n","<br>\n","\n","## Given the real estate data answer the following questions:\n","\n","\n","**Is their a correlation between property tax and transaction price (tx_price)?**\n","\n","Their is a high correlation between property taxes and transaction prices.  This is made clear by inspecting the heatmap below. The data and heatmap make sense as a homes property taxes are based on the price of the home.\n","\n","<br>\n","\n","**Does lifestyle features effect tx_price?**\n","\n","No."]},{"cell_type":"markdown","metadata":{"id":"9J2FIiZz_Ya_","colab_type":"text"},"source":["<hr>\n","\n","# Data Schema\n","- **tx_price:** The sell price of the home\n","- **LotArea:** Lot size in square feet\n","- **Neighborhood:** Physical locations within Ames city limits\n","- **BldgType:** Type of dwelling\n","       **1Fam:**\tSingle-family Detached\t\n","       **2FmCon:**\tTwo-family Conversion; originally built as one-family dwelling\n","       **Duplx:**\tDuplex\n","       **TwnhsE:**\tTownhouse End Unit\n","       **TwnhsI:**\tTownhouse Inside Unit\n","- **YearBuilt:** Original construction date\n","- **YearRemodAdd:** Remodel date (same as construction date if no remodeling or additions)\n","- **MasVnrArea:** Masonry veneer area in square feet\n","- **TotalBsmtSF:** Total square feet of basement area\n","- **CentralAir:** Central air conditioning\n","- **1stFlrSF:** irst Floor square feet\n","- **2ndFlrSF:** Second floor square feet\n","- **GrLivArea:** Above grade (ground) living area square feet\n","- **BsmtFullBath:** Basement full bathrooms\n","- **BsmtHalfBath:** Basement half bathrooms\n","- **FullBath:** Full bathrooms above grade\n","- **HalfBath:** Half baths above grade\n","- **BedroomAbvGr:** Bedrooms above grade (does NOT include basement bedrooms)\n","- **KitchenAbvGr:** Kitchens above grade\n","- **TotRmsAbvGrd:** Total rooms above grade (does not include bathrooms)\n","- **Fireplaces:** Number of fireplaces\n","- **GarageType:** Garage location\n","       2Types\tMore than one type of garage\n","       Attchd\tAttached to home\n","       Basment\tBasement Garage\n","       BuiltIn\tBuilt-In (Garage part of house - typically has room above garage)\n","       CarPort\tCar Port\n","       Detchd\tDetached from home\n","       NA\tNo Garage\n","- **GarageYrBlt:** Year garage was built\n","- **GarageCars:** Size of garage in car capacity\n","- **GarageArea:** Size of garage in square feet\n","- **MoSold:** Month Sold (MM)\n","- **YrSold:** Year Sold (YYYY)\n","- **SalePrice:** Dollar amount unit sold for\n","- **Siding:** Exterior covering on house\n","\n","The outline to follow has been included down below. Each topic has the steps included with a blank cell, feel free to create as many new cells to keep your code separated.\n","\n","Extra challenge:  If you want to make a categorical prediction, create a new column and bin the SalePrice into three categories (small, medium and large) then remove the SalePrice and try to predict that new column."]},{"cell_type":"markdown","metadata":{"id":"hPIr0KPA_lK5","colab_type":"text"},"source":["<hr>\n","\n","# Setup"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eaMOBuOF_xsb"},"source":["### Import Libraries\n","\n","*   Numpy\n","*   pandas\n","*   matplotlib\n","*   seaborn\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ErewWMkv_xsd"},"source":["##### Import numpy"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Mw882ZpU_xse","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AkZsjeeY_xsh"},"source":["##### Import pandas"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-8oDi95d_xsi","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6raGZu_z_xsk"},"source":["##### Import matplotlib"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4nGhg0Du_xsl","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ulbRwzBf_xsq"},"source":["##### Import seaborn"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ttUrqqeq_xsr","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y6s2iblq2iN8"},"source":["#### Library Configurations\n","Specifically use seaborn graphs rather than matplotlib's graphs\n","and also showcase all of the DataFrame's columns and rows\n","```python\n","sns.set() # make seaborn override the styling of matplotlib graphs\n","pd.set_option('display.max_columns', None) # display all columns\n","pd.set_option('display.max_rows', None) # display all rows\n","```"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3rGYEABq2iN9","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TQT_3BQO8tf-","colab_type":"text"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QtTVPUZ34COg"},"source":["### Import Data\n","Read in the real estate dataset using the following path and store it in a variable called `df`.\n","\n","## Import the cleaned employee dataset\n","- Use pandas' `read_csv()` function\n","\n","#### Pandas' `read_csv()` parameters:\n","- `filepath_or_buffer` (string): path of csv to import\n","\n","```python \n","filepath_or_buffer = './data/dirty-midterm-real-estate-data.csv'\n","```"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PVsiNsWs4COh","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CyxVU1kM_-qI","colab_type":"text"},"source":["<hr>"]},{"cell_type":"markdown","metadata":{"id":"kqhZnyB5AVi7","colab_type":"text"},"source":["# Exploratory Data Analysis - EDA\n","It is a good practice to understand the data first and try to gather as many insights from it. EDA is all about making sense of data in hand, before getting them dirty with it."]},{"cell_type":"markdown","metadata":{"id":"7BP0JuBTCnk8","colab_type":"text"},"source":["### Display Head "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sgbRu-C03ytC","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kEOvAvtsC0n4","colab_type":"text"},"source":["### Display Tail"]},{"cell_type":"code","metadata":{"id":"HTi6jxpNdqAV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Zjf-bNAB3ytB"},"source":["### Display the dimensions of the dataset\n","\n","This will become important for us later once we manipulate the DataFrame.\n","We will use the shape dimensions to make sure we are manipulating the DataFrame correctly.\n","\n","i.e.\n","  - deleting rows and columns\n","  - adding columns\n","\n","\n","#### Use the `.shape` property of the DataFrame to find out the shape of the dataset\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"42gIabyP3ys9","colab":{}},"source":["# Dataframe dimensions\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Pr6NLBJ13ys7"},"source":["### Display the data types of our features\n","- Use the DataFrame's `info()` method to find out more about the DataFrame, such as the column data types and column names "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Lw4JUj1t3yss","colab":{}},"source":["# Column datatypes\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4-jclahM3ysr"},"source":["#### Question: \n","What columns are text, or classified as categorical data? "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MqcBZ3jL3ysp"},"source":["- property_type\n","- exterior_walls\n","- roof"]},{"cell_type":"markdown","metadata":{"id":"v0lBy1mttL0O","colab_type":"text"},"source":["<hr> \n","\n","<br>\n","\n","# Distributions Of Numeric Features\n","- Use the DataFrame's `hist` method to create a histogram for each numerical features \n","\n","#### Arguments to consider passing in:\n","- (optional) `bins:` splits the data into groups based on the number specified \n","- (optional) `xrot:` rotates x-axis labels counter-clockwise; <span style=\"color:red\"> really useful for long x index labels </span>\n","- (optional) `figsize`: (float, float) width, height in inches.\n","- (optional) `color:` colors the histogram with one of these values {'b', 'g', 'r', 'c', 'm', 'y', 'k', 'w'}"]},{"cell_type":"code","metadata":{"id":"8fYp_R01tL0Q","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iz_xki2OtL0s","colab_type":"text"},"source":["## Fix Numerical Structural Errors\n","\n","The next bucket under data cleaning involves fixing structural errors.\n","\n","Here is a list of some structural errors:\n","- duplicate rows\n","- unwanted values in columns **i.e.** blank values\n","- outliers in columns\n","- features (columns) can suffer from sparse classes, meaning features that have a lot of different uniuqe values\n","- mislabeled classes ( mislabeled values)\n","\n","<br id=\"drop\">\n","\n","### Drop unwanted observations\n","\n","#### Drop all duplicate observations using the DataFrame's `drop_duplicates()` method\n","\n","##### `drop_duplicates()` parameters: \n","- `subset` (string): Subset takes a column or list of column label. It’s default value is none. After passing columns, it will consider them only for duplicates.\n","-`keep` (string): keep is to control how to consider duplicate value. It has only three distinct value and default is ‘first’.\n","  - If ‘first’, it considers first value as unique and rest of the same values as duplicate.\n","  - If ‘last’, it considers last value as unique and rest of the same values as duplicate.\n","  - If `False`, it consider all of the same values as duplicates\n","- `inplace` (boolean): default False, Whether to drop duplicates in place or to return a copy\n","\n","**Return type**: DataFrame with removed duplicate rows depending on Arguments passed. i.e. if inplace == True then nothing will be returned \n","\n","#### Generic Example: \n","```python \n"," df = df.drop_duplicates()\n","\n"," # inplace example\n","  df.drop_duplicates(inplace=True)\n","```\n","\n","\n","### Check the shape of the real estate DataFrame before removing the duplicates"]},{"cell_type":"code","metadata":{"id":"tlBza0sqQ5sn","colab_type":"code","colab":{}},"source":["# Print shape of dataframe\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kZ0fOZXdQ4nq","colab_type":"text"},"source":["### Delete duplicates with the inplace argument set as true\n"]},{"cell_type":"code","metadata":{"id":"lK8eQ8qERDoi","colab_type":"code","colab":{}},"source":["# Drop any duplicates\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"arTXjZetRC_K","colab_type":"text"},"source":["### Check the shape of the real estate DataFrame to see if any changes were made"]},{"cell_type":"code","metadata":{"id":"EwsGi1JEtL0v","colab_type":"code","colab":{}},"source":["# Print shape of new dataframe to compare\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5GEQ1pNsEtGi","colab_type":"text"},"source":["#### How many rows were duplicates?\n","\n"]},{"cell_type":"markdown","metadata":{"id":"M8aIUbcqtL03","colab_type":"text"},"source":["<br id=\"structural\">\n","\n","### Let us look at which columns have blank values\n","\n","Hint: \n","- Use the DataFrame's `isnull()` method\n","- Chain the `sum()` method on the return of the `isnull()` method to tally up the number of null values in each column\n"]},{"cell_type":"code","metadata":{"id":"ActsGBZ-JHGS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MUcE5R41oGXX","colab_type":"text"},"source":["### Drop rows with more than twenty columns with null values "]},{"cell_type":"markdown","metadata":{"id":"J8CFyuHRh_O6","colab_type":"text"},"source":["`dropna` parameters: \n","- `thresh` (int): number of columns required to have null values in order for the row to be dropped\n","- `inplace` (boolean): default False, Whether to drop duplicates in place or to return a copy\n"]},{"cell_type":"code","metadata":{"id":"HGfsw_gMhHlO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7Fq1lUNfqDFQ","colab_type":"text"},"source":["### Let us look at the number of blank values each columns have to see if we did in fact delete the rows with more than twenty null values\n","\n","Hint: \n","- Use the DataFrame's `isnull()` method\n","- Chain the `sum()` method on the return of the `isnull()` method to tally up the number of null values in each column"]},{"cell_type":"code","metadata":{"id":"aOoQhsB4qBJ4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QTI-Vum-I5ri","colab_type":"text"},"source":["### Let us remove blank values from the 'basement' column"]},{"cell_type":"markdown","metadata":{"id":"lzEXH84ltL09","colab_type":"text"},"source":["#### Let's see the different unique values of the `basement` column\n","- Use the series' `.unique()` method to display the unique values of the 'basement` column"]},{"cell_type":"code","metadata":{"id":"NCd8VlPDtL0_","colab_type":"code","colab":{}},"source":["# Display unique values of 'basement'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8AEeP4xxtL1E","colab_type":"text"},"source":["#### Fill missing <code style=\"color:steelblue\">'basement'</code> values with the value <code style=\"color:crimson\">0</code> to turn <code style=\"color:steelblue\">'basement'</code> into a true `indicator` variable.\n","\n","We will do this by using the series' `fillna()` method.\n","#### `fillna()` parameters:\n","- value (scalar, dict, Series, or DataFrame): The value to use to fill holes (e.g. 0)\n","-inplace (boolean): default False, if `True`, fill in-place\n","\n","\n","#### Fill in missing 'basement' values with 0"]},{"cell_type":"code","metadata":{"id":"jmS4UdqetL1F","colab_type":"code","colab":{}},"source":["# Missing basement values should be 0\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HECFtyUVtL1I","colab_type":"text"},"source":["#### Confirm that we have a true indicator variable for the `basement` series (column):"]},{"cell_type":"code","metadata":{"id":"PIKSI88ftL1J","colab_type":"code","colab":{}},"source":["# Display unique values of 'basement'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eQBnCnQ4tL19","colab_type":"text"},"source":["<hr>\n","<br id=\"outliers\">\n","\n","## Remove unwanted outliers\n","\n","### Outliers recap\n","\n","An **outlier** is a data point that differs significantly from other observations in a dataset. An outlier may be due to variability in a measurement or it may indicate that there was an experimental error. An outlier can cause serious problems if not evaluated and addressed.\n","Outliers can cause problems with certain types of models.\n","\n","<br>\n","\n","### Analyze the box and violin plot of your target variable, `tx_price`, since that's the variable that you're actually trying to predict. \n","\n","#### Use the seaborn's boxplot and violinplot functions to show distribution of the `tx_price` column. \n","\n","#### To show multiple plots on a single figure alter the following generic code:\n","\n","```python \n","# Import the matplotlib.pyplot submodule and name it plt\n","import matplotlib.pyplot as plt\n"," \n","# Create a Figure and an Axes with plt.subplots\n","fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(20, 5))\n","\n","# Style Seaborn figure To Have White Background\n","sns.set_style('whitegrid') \n","\n","# Plot graphs on axes\n","left_plot = sns.countplot(x='feature_name', data=df, ax=ax[0])\n","right_plot = sns.violinplot(x='feature_name', data=df, ax=ax[1])\n","\n","# setup labels for left graph\n","ax[0].set_title(\"Title Of Graph\")\n","ax[0].set_xlabel('x_label')\n","ax[0].set_ylabel('y_label')\n","\n","# setup labels for right graph\n","ax[1].set_title(\"Title Of Graph\")\n","ax[1].set_xlabel('x_label')\n","ax[1].set_ylabel('y_label')\n","\n","# Add space between plots\n","fig.tight_layout() \n","```\n","\n","#### sns.boxplot() and sns.violin() parameters:\n","- `x` (string): axis parameter provide the numerical column (series) name\n","- `y` (optional) (string): axis parameter provide the categorical column (series) name\n","- `data` (DataFrame): Dataset for plotting\n","- `ax`  ( optional) (matplotlib Axes): Axes object to draw the plot onto, otherwise uses the current Axes.\n","\n","<br>"]},{"cell_type":"code","metadata":{"id":"4yG6-xc9tL2F","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zy-lP0JVOXXZ","colab_type":"text"},"source":["#### Does the graph look skewed, why would this be?\n","\n","Yes, because there is an outlier altering the shape of the data and distribution.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wfOlD3Kwtmdc","colab_type":"text"},"source":["**Sort tx_price series and display the top 5 samples.**\n","* You can sort a Series with the <code style=\"color:steelblue\">.sort_values()</code> method.\n","\n","#### Series' `sort_values()` parameters:\n","- `ascending` (boolean): By default, it's True which sort the values from low to high. Passing in False will sort the values from high to low.\n","\n","**Tip:** You can chain functions together. For example print the head of the return value of `.sort_values()`"]},{"cell_type":"code","metadata":{"id":"qPf0Hxj6u0NV","colab_type":"code","colab":{}},"source":["# Sort df['tx_price'] and display the top 5 samples\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gZNWfisgtdik","colab_type":"text"},"source":["#### **Remove observations with <code style=\"color:steelblue\">tx_price</code> greater than 800,000 dollars**\n","\n","#### Print the shape of the data before you manipulate it \n"]},{"cell_type":"code","metadata":{"id":"vI0XQSbSPPxI","colab_type":"code","colab":{}},"source":["# print length of df\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O3CfegJdPPH_","colab_type":"text"},"source":["#### Remove observations with `tx_price` greater than 800,000 dollars\n","- use a boolean mask (series) to filter the observations that match the condition of only selecting properties with sqft being greater that 800,000  (filter to keep only wanted observations)\n","* Overwrite the existing <code style=\"color:steelblue\">df</code> object\n"]},{"cell_type":"code","metadata":{"id":"sfJ8u2Rdvbq0","colab_type":"code","colab":{}},"source":["# Remove tx_price outliers\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"arJWynV4PUMi","colab_type":"text"},"source":["#### Print the shape to see if the manipulation took place"]},{"cell_type":"code","metadata":{"id":"XOyb_zEfve4L","colab_type":"code","colab":{}},"source":["# print length of df\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ru8_FXdQy1je","colab_type":"text"},"source":["#### Use the seaborn's boxplot and violinplot functions to show distribution of the `tx_price` column again to see the changes in distribution\n"]},{"cell_type":"code","metadata":{"id":"C3PLs1n6yxOf","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ru8ijjzKv2aF"},"source":["#### What's the difference between box plots and violin plots?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0Pr7GQlyv2aA"},"source":["A Violin Plot is similar to a boxplot except we see the distributions in a different representation as well as the IQR and Median markers."]},{"cell_type":"markdown","metadata":{"id":"WB5-Eec1zJgw","colab_type":"text"},"source":["#### Describe the difference in distribution. What type of distribution does the plot look like?\n","\n","It looks less skewed and more of a normal distribution"]},{"cell_type":"markdown","metadata":{"id":"1Zb4t2gmtL2K","colab_type":"text"},"source":["<br>\n","\n","### Analyze other feature distributions\n","#### Plot the violin plots for <code style=\"color:steelblue\">'beds'</code>, <code style=\"color:steelblue\">'sqft'</code>, and <code style=\"color:steelblue\">'lot_size'</code> on a single figure\n","\n","##### Feel free to reference the code above "]},{"cell_type":"code","metadata":{"id":"PvIaG7QQtL2K","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YR7v57dftL2N","colab_type":"text"},"source":["#### Among those three features, which one looks like it has a outlier? Why do you say this?\n","\n","It looks like <code style=\"color:steelblue\">lot_size</code> has a potential outlier! \n","* Look at its long and skinny tail.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"10FqBhIyRFtI","colab_type":"text"},"source":["<br>\n","\n","#### Let's look at the largest 5 lot sizes just to confirm that we have an outlier\n","**Sort <code style=\"color:steelblue\">df['lot_size']</code> and display the top 5 samples.**\n","* You can sort a Series with the <code style=\"color:steelblue\">.sort_values()</code> function.\n","\n","#### DataFrames `sort_values()` parameters:\n","- `ascending` (boolean): By default, it's True which sort the values from low to high. Passing in False will sort the values from high to low.\n","\n","**Tip:** You can chain functions together. For example print the head of the return value of `.sort_values()`"]},{"cell_type":"code","metadata":{"id":"IjRnALV0tL2O","colab_type":"code","colab":{}},"source":["# Sort df.lot_size and display the top 5 samples\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"agd5HK33RnND"},"source":["#### **Remove observations with `lot_size` greater than 500,000 sqft**\n","\n","#### Print the shape of the data before you manipulate it \n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FNpY-1pBRnNG","colab":{}},"source":["# print length of df\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"YTZmPQWERnNK"},"source":["#### Remove observations with `lot_size` greater than 500,000 dollars\n","- use a boolean mask (series) to filter the observations that match the condition of only selecting properties with sqft being greater that 800,000  (filter to keep only wanted observations)\n","* Overwrite the existing ```df``` object\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tMGhi-R5RnNL","colab":{}},"source":["# Remove lot_size outliers\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ut9T2rSFRnNN"},"source":["#### Print the shape to see if the manipulation took place"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PQjPE9FjRnNO","colab":{}},"source":["# print length of df\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bBCOiPlVb0Cl","colab_type":"text"},"source":["### Show the distribution for the lot_size Column again to see the difference in distribution"]},{"cell_type":"code","metadata":{"id":"IczagZnLcDXH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wBB6_VSL95IP","colab_type":"text"},"source":["# Distributions of Categorical Features\n","\n","Next, let's take a look at the distributions of our categorical features.\n","<br>\n","\n","Display summary statistics for categorical features.\n","\n","#### DataFrames `describe()` method parameters:\n","- `include` (string, or list of strings): which can take in an the following value `\"object\"` to show only information about categorical features.  "]},{"cell_type":"code","metadata":{"id":"jKISwUTY95IP","colab_type":"code","colab":{}},"source":["# Summarize categorical features\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pl4wG5tS0Hen","colab_type":"text"},"source":["### Let's loop through our categorical DataFrame and show each of the feature's distributions\n","\n","When we loop through (iterate over) a pandas DataFrame we will access the column (feature) names. \n","\n","This is useful because now we are not hard coding feature names for desired operations on multiple columns of data. \n","\n","<br>\n","\n","**Tip:** The following line of code will return a DataFrame with all of the categorical features\n","```python \n","df.select_dtypes(include=['object'])\n","```\n","<br>\n","\n","\n","Once we have access to the feature name let us do the following:\n","- show the distribution of the feature by creating a countplot using `sns.countplot()` \n","- print the value counts of each feature using the Series' `value_counts()` method \n","- print a blank line \n","\n","#### sns.countplot() parameters:\n","- (optional) `x` (string: series name): specify the values for the x axis\n","- (optional) `y` (string: series name): specify the values for the y axis\n","- `data` (DataFrame, array, or list of arrays): Dataset for plotting\n","\n","#### value_counts() parameters:\n","- `dropna` (boolean): default True; If `True` don’t include counts of NaN, if `False` include counts of NaN values\n"]},{"cell_type":"code","metadata":{"id":"HIa-xlNQ95IS","colab_type":"code","colab":{}},"source":["# Countplot for each categorical feature\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LpHL885KYUxm","colab_type":"text"},"source":["## Fix Categorical Structural Errors\n"]},{"cell_type":"markdown","metadata":{"id":"uKJ68xCGeSXV","colab_type":"text"},"source":["One thing we should notice is that there are observations (rows) with all categorical columns having `0` as a value.\n","\n","### Investigate these rows with '0' as column values \n","- Use a boolean series to identify the index of the row with the value of `0` for the categorical features\n","\n","**Tip:**\n","- Pandas `Series.str.contains()` function is used to test if pattern or regex is contained within a string of a Series or Index.\n","\n","Example: \n","```python\n","df[df['feature_name'].str.contains('partial value or exact value to look for')]\n","```\n","\n","**Tip:**\n","- you can use a `|` (or) operator to handle if multiple conditions might occur\n","\n","Example:\n","```python\n","df[( (df['feature_one'].str.contains('0')) | (df['feature_two'].str.contains('0')) | (df['feautre_three'].str.contains('0'))  )]\n","```\n","\n","If any of the conditions are true we will see those rows\n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"VODRvz_ABvyK","colab_type":"text"},"source":["\n","### Print the rows with `'0'` as a value for the categorical columns (features) \n","\n"]},{"cell_type":"code","metadata":{"id":"IHEFzvvYh0Gi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XMvId1Qc_SRj","colab_type":"text"},"source":["We can see that the row indexed at number 2 has `0` and `'0'` as values for each of the columns. This is something we saw while displaying the head but sometimes these rows will not be present in the head or tail of the DataFrame. It is just something we have to look out for and remember for future datasets. In our case we identified this situation by using visualizations and plots to find this outlier observation. \n","\n","We can remove this row from the DataFrame by using the pandas `drop()` DataFrame method.\n","\n","#### Pandas DataFrame drop() method parameters:\n","- `labels` (single label string or integer or a list of strings and integers): Index or column labels to drop.\n","- `axis` : {0 or ‘index/row’, 1 or ‘columns’}, default 0\n","Whether to drop labels from the index (0 or ‘index/row’) or columns (1 or ‘columns’). \n","- `inplace` (bool): default False; If True, do operation inplace and return None.\n","\n","<br>\n","\n","### Delete this observation\n"]},{"cell_type":"code","metadata":{"id":"iZVMSLiTAFV0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HrJxavZz7yv1","colab_type":"text"},"source":["### Because we removed a few rows from the DataFrame let's reset the index of the DataFrame\n","\n","The Series' `reset_index()` method will generate a new DataFrame or Series with the index reset. This is useful when the index needs to be treated as a column, or when the index is meaningless and needs to be reset to the default before another operation.\n","\n","#### Series' `reset_index()` parameters:\n","- drop (bool): default False, will reset the indexes and create a new column with the old indexes. If 'True` the method drops the current index of the DataFrame and replaces it with an index of increasing integers. \n"]},{"cell_type":"markdown","metadata":{"id":"CyDKA9roC2kv","colab_type":"text"},"source":["\n","### Reset the index of the DataFrame:\n","- reassign the `df` variable with the DataFrame's `reset_index()` method\n","- set the `reset_index()` `drop` parameter to `True`\n"]},{"cell_type":"code","metadata":{"id":"kN6nqf_dljNa","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"A53BJ4P5ByWr"},"source":["### Confirm that we deleted all the rows with `'0'` as a value for the categorical columns (features) \n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MXjmSeh0ByWr","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EWc8Ulh39CGF","colab_type":"text"},"source":["<br>\n","\n","### Handling NAN values\n","It seems that there are missing values in the categorical features, we will need to remove them if we want to have a well performing model.\n","\n","We will do this by using the series `fillna()` method.\n","#### `fillna()` parameters:\n","- value (scalar, dict, Series, or DataFrame): The value to use to fill null values (e.g. \"missing\")\n","-inplace (boolean): default False, if `True`, fill in-place\n","\n","#### Generic Example: \n","```python \n"," df['feature_name'] = df['feature_name'].fillna(value=\"missing\")\n","\n"," # inplace example\n"," df['feature_name'].fillna(value=\"missing\", inplace=True)\n","```\n","\n","#### Fill in missing 'exterior_walls' with a the value 'missing'"]},{"cell_type":"code","metadata":{"id":"y43N7d1RYu9m","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8cKIWig9ZUAo"},"source":["#### Confirm that we have a true indicator variable for the `basement` series (column):\n","\n","- Use the series' `unique()` method to show unique values of a column"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NCmAhE2pZUAq","colab":{}},"source":["# Display unique values of 'basement'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xeMdiszlZfaN","colab_type":"text"},"source":["### Fill in missing 'exterior_walls' with a the value 'missing'"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"QnfN957oZkRI","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7-Ve8VBeZkRN"},"source":["#### Confirm that we have a true indicator variable for the `basement` series (column):\n","\n","- Use the series' `unique()` method to show unique values of a column"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E4DBE7N9ZkRO","colab":{}},"source":["# Display unique values of 'basement'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7RbMps_j3p5G","colab_type":"text"},"source":["<hr>\n","\n","<br>\n","\n","## Data Cleaning "]},{"cell_type":"markdown","metadata":{"id":"xzHmbOhotL1O","colab_type":"text"},"source":["### Clean-up the `roof` column (series)\n","\n","#### Recap:\n","We mentioned that features (columns) can suffer from  having to many unique values, refered to as noise. This can hurt machine learning algorithms because it will try to learn to seperate or cluster too many unique values. If we can remove the amount of unique values in a series (column) then the machine learning algorithm can perform better.\n","\n","**Remember** having more features (columns/series) and unique values for each feature doesn't mean a better machine learning algorithm. Infact it will increase the noise and decrease the efficiency and can result in overfitting.\n","\n","#### Using seaborn's countplot, plot the `roof` distribution\n","\n","#### sns.countplot() parameters:\n","- (optional) `x` (string: series name): specify the values for the x axis\n","- (optional) `y` (string: series name): specify the values for the y axis\n","- `data` (DataFrame, array, or list of arrays): Dataset for plotting"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"0B0-IPP6tL1R","colab_type":"code","colab":{}},"source":["# Class distributions for 'roof'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_BQSVXyzq9CF"},"source":["Notice that there are some typos and inconsistent capitalization in the `roof` feature."]},{"cell_type":"markdown","metadata":{"id":"UGFnFcRUtL1W","colab_type":"text"},"source":["#### Using the series' `replace()` method replace values of a column (series)\n","\n","#### series' `replace()` method parameters:\n","- `to_replace` (str, regex, list, dict, Series, int, float, or None): How to find the values that will be replaced.\n","-value (scalar, dict, list, str, regex, default None): Value to replace any values matching to_replace with. \n","- `inplace` (boolean): default False, Whether to replace values in place or to return a copy\n","\n","**Example:**\n","```python \n","df['feature'].replace(to_replace='desired_value_to_replace', value='desired_value', inplace=True)\n","```\n","\n","**Note:** We can also provide a list of values as an argument to the `to_replace` parameter\n","\n","**Example:**\n","```python \n","df['feature'].replace(to_replace = ['a_desired_value_to_replace', 'another_desired_value_to_replace'], value = 'desired_value', inplace=True)\n","```\n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"X4gF-jJgudxL","colab_type":"text"},"source":["\n","#### Replace `composition` with `Composition` "]},{"cell_type":"code","metadata":{"id":"OHSLV0_PtL1X","colab_type":"code","colab":{}},"source":["# 'composition' should be 'Composition'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"alF-2vJUfS9I","colab_type":"text"},"source":["#### Replace `asphalt` with `Asphalt` "]},{"cell_type":"code","metadata":{"id":"zUVtxUZ_tL1d","colab_type":"code","colab":{}},"source":["# 'asphalt' should be 'Asphalt'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nUow_lFMfbxu","colab_type":"text"},"source":["#### Replace `'shake-shingle'`, `'Ashpalt, shake-shingle'`, `'asphalt,shake-shingle'` with the value `'Shake Shingle'`\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dGC6moIaqUrU","colab":{}},"source":["# 'shake-shingle' and 'asphalt,shake-shingle' should be 'Shake Shingle'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rBPHiB-nquZT","colab_type":"text"},"source":["#### Group `'Composition'` and `'Wood Shake/ Shingles'` into the `'Composition Shingle'` class.\n"]},{"cell_type":"code","metadata":{"id":"ok3Zz4kXljOD","colab_type":"code","colab":{}},"source":["# Group 'Composition' and 'Wood Shake/ Shingles' into 'Composition Shingle'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-axdcWwHljOG","colab_type":"text"},"source":["#### Group `Gravel/Rock'`, `'Roll Composition'`, `'Slate'`, `'Built-up'`, `'Asbestos'`, and `'Metal'` into the `'Other'` class."]},{"cell_type":"code","metadata":{"id":"fu7sddd0ljOG","colab_type":"code","colab":{}},"source":["# List of classes to group\n","\n","# Group other classes into 'Other'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xWx6ipuvigfv"},"source":["#### Using seaborn's countplot, plot the `roof` distribution to see the changes \n","\n","#### sns.countplot() parameters:\n","- (optional) `x` (string: series name): specify the values for the x axis\n","- (optional) `y` (string: series name): specify the values for the y axis\n","- `data` (DataFrame, array, or list of arrays): Dataset for plotting"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oSdKqLAxigf_","colab":{}},"source":["# Class distributions for 'roof'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0NUhlZpvtL1m","colab_type":"text"},"source":["### Clean-up `exterior_walls` column (series)\n"]},{"cell_type":"markdown","metadata":{"id":"5kBi6ISgtiAL","colab_type":"text"},"source":["\n","#### Plot the class distributions for `'exterior_walls'` using a countplot\n","\n","#### sns.countplot() parameters:\n","- (optional) `x` (string: series name): specify the values for the x axis\n","- (optional) `y` (string: series name): specify the values for the y axis\n","- `data` (DataFrame, array, or list of arrays): Dataset for plotting"]},{"cell_type":"code","metadata":{"id":"gSUKHEN7tL1o","colab_type":"code","colab":{}},"source":["# Class distributions for 'exterior_walls'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mzLc6NXjtL1s","colab_type":"text"},"source":["#### Replace any instances of `'Rock, Stone'` with `'Masonry'`\n","- Note: `Rock, Stone` is one value not two"]},{"cell_type":"code","metadata":{"id":"JxqQNKnTtL1t","colab_type":"code","colab":{}},"source":["# 'Rock, Stone' should be 'Masonry'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_n0ViLO_tL1y","colab_type":"text"},"source":["#### Replace any instances of `'Concrete'` and `'Block'` with `'Concrete Block'` "]},{"cell_type":"code","metadata":{"id":"bU6TAshdtL1z","colab_type":"code","colab":{}},"source":["# 'Concrete' and 'Block' should be 'Concrete Block'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"83sO-lXnljNu","colab_type":"text"},"source":["#### Group <code style=\"color:crimson\">'Wood Siding'</code> and <code style=\"color:crimson\">'Wood Shingle'</code> into the existing <code style=\"color:crimson\">'Wood'</code> value\n"]},{"cell_type":"code","metadata":{"id":"7X3PDschljNv","colab_type":"code","colab":{}},"source":["# Group 'Wood Siding' and 'Wood Shingle' with 'Wood'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-wbH8IV2ljNy","colab_type":"text"},"source":["#### Group `'Stucco'`, `'Asbestos shingle'`, `'Concrete Block'`, and `'Masonry'` into the existing `'Other'` value"]},{"cell_type":"code","metadata":{"id":"3B2e5p04ljN2","colab_type":"code","colab":{}},"source":["# List of classes to group\n","\n","# Group other classes into 'Other'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Al7evjuTtL13","colab_type":"text"},"source":["#### Using seaborn's countplot, plot the `exterior_walls` distribution to see the changes \n","\n","#### sns.countplot() parameters:\n","- (optional) `x` (string: series name): specify the values for the x axis\n","- (optional) `y` (string: series name): specify the values for the y axis\n","- `data` (DataFrame, array, or list of arrays): Dataset for plotting"]},{"cell_type":"code","metadata":{"id":"eJArsyd3tL14","colab_type":"code","colab":{}},"source":["# Class distributions for 'exterior_walls'\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ewtzIPq5DskT","colab_type":"text"},"source":["<hr>\n","\n","<br>\n","\n","# Correlations\n","\n","Let's take a look at the relationships between **numeric features** and **other numeric features**.\n","\n","<br>\n","\n","### Create a `correlations` dataframe from `df`\n","\n","- Use pandas' DataFrame `.corr()` method to show you all of the correlations between all the columns of the DataFrame.\n","- Save this correlations DataFrame into a variable called `correlations`\n","\n","**Note:** The default parameters utilizes the pearson correlation coefficient.\n","\n"]},{"cell_type":"code","metadata":{"id":"zSLisCIZwc4l","colab_type":"code","colab":{}},"source":["#Calculate correlations between numeric features\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9vnAdc5Cwccz","colab_type":"text"},"source":["<br>\n","\n","### Visualize the correlation grid using a seaborn heatmap to make it easier to digest\n","\n","#### Recap:\n","A **heat map** is a graphical representation of data where the individual values contained in a matrix are represented as colors.\n","\n","#### seaborn.heatmap() parameters:\n","- `data` (DataFrame): rectangular dataset, 2D dataset\n","- `annot` (boolean): argument controls whether to annotate each cell with its value. By default, it's `False`.\n","\n","**Tips:**\n","- To make the chart cleaner, multiply the <code style=\"color:steelblue\">correlations</code> DataFrame by 100 before passing it to the heatmap function.\n","- Pass in the argument <code style=\"color:steelblue\">fmt=<span style=\"color:crimson\">'.0f'</span></code> to format the annotations to a whole number.\n","- we will use a mask that will help us cut out the duplicates correlation values.\n","\n","#### Creation of heatmap:\n","```python \n","# Calculate correlations between numeric features\n","correlations = df.corr()\n","\n","# Make the figsize 15 x 15\n","plt.figure(figsize=(15, 15))\n","\n","# Generate a mask for the upper triangle\n","mask = np.zeros_like(correlations, dtype=np.bool)\n","mask[np.triu_indices_from(mask)] = True\n","\n","# Plot heatmap of annotated correlations\n","correlations = correlations * 100\n","\n","# Plot heatmap of correlations\n","sns.heatmap(data=correlations, annot=True, fmt='.0f', mask=mask)\n","\n","# Uncomment the code below to fix the heatmap being cut off\n","# b, t = plt.ylim() # discover the values for bottom and top\n","# b += 0.5 # Add 0.5 to the bottom\n","# t -= 0.5 # Subtract 0.5 from the top\n","# plt.ylim(b, t) # update the ylim(bottom, top) values\n","\n","# Show the heatmap\n","plt.show() \n","```\n","#### Try it yourself:"]},{"cell_type":"code","metadata":{"id":"ITKvg81895IU","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q9YtYHg4y15Y","colab_type":"text"},"source":["#### **Is their a correlation between property tax and transaction price (tx_price)?**\n","\n","Their is a high correlation between property taxes and transaction prices.  This is made clear by inspecting the heatmap below. The data and heatmap make sense as a homes property taxes are based on the price of the home.\n","\n","<br>"]},{"cell_type":"markdown","metadata":{"id":"4Xw05YQXzKGm","colab_type":"text"},"source":["#### **Does lifestyle features effect tx_price?**\n","Lifestyle features include the following:\n","- restaurants\n","- groceries\n","- nightlife\n","- cafes\n","- shopping\n","- arts_entertainment\n","- beauty_spas\n","- active_life\n","\n","Not really, the pearson coefficent correlation values are close to 0 meaning there is no correlation"]},{"cell_type":"markdown","metadata":{"id":"WecX4gGEl6Hy","colab_type":"text"},"source":["<hr>\n","\n","<br>\n","\n","# Feature Engineering\n","\n","We noticed that there are close to no correlations reguarding lifestyle features.\n","\n","**Remember:** \n","It is important to note that having more features (columns/series) and unique values for each feature doesn't mean a better machine learning algorithm. Infact it will increase the noise and decrease the efficiency and can result in overfitting.\n","\n","**Note:** Everything we have done in this notebook will effect the machine learning algorithm. That being said, it is important to note that this process is iterative. Maybe grouping unique values (sparse amount of classes) or combining columns actually brings down the accuracy and performance of the model. The only way to find out is by analyzing the results of the model and then come back to this notebook to tinker with the dataset in different ways and see if we get more performant models. Of course knowing domain knowledge helps but typically domain knowledge comes into play after the first iteration of creating a model. \n","\n","Ultimately we are only able to see plots in smaller dimensions i.e. no more than three dimensions. That being said maybe us combining features or dropping only based on a pearson correlation coefficent (comparing two features numerical with on another) may be hurtful because we can not see higher dimensional clustering.\n","\n","[Check out this video to get an understanding of what machine learning is doing with dimensional space](https://www.youtube.com/watch?v=wvsE8jm1GzE)\n","\n","<br>\n","\n","## That being said let's group the lifestyle features together to for applicational practices\n","\n","### Create a list of lifestyle column names"]},{"cell_type":"code","metadata":{"id":"6dK6VTzODdAb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f6ncrmlIKYt_","colab_type":"text"},"source":["In order for us to group these features together we need to normailize the values. The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values.\n","\n","We will do this with the following logic.\n","\n","First create a new variable to hold a new DataFrame containing all of the lifestyle features, call this variable `lifestyle_df`.\n","\n","Then for each column of the lifestyle features DataFrame compute the mean and standard deviation. Once we have these values we will perform element wise operations.\n","\n","More specifically we will subtract each element in each column the dataframe from it's mean of that specific column and then we will divide this value with the standard deviation of that column. \n","\n","**Logic:**\n","```python \n","normalized_df = ( df - df.mean() ) / df.std()\n","```"]},{"cell_type":"markdown","metadata":{"id":"5xk4MkHSLwZV","colab_type":"text"},"source":["### Create A Lifestyle DataFrame\n"]},{"cell_type":"code","metadata":{"id":"RlZh4Z12MCRo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"agklkSG_MJA2","colab_type":"text"},"source":["### Print the head of the new DataFrame to make sure we did the operation correctly"]},{"cell_type":"code","metadata":{"id":"cPL-dL_yMQiY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ptRd1X8XMUjQ","colab_type":"text"},"source":["Normalize the `lifestyle_df` and save the result in a variable called `normalized_lifestyle_df`"]},{"cell_type":"code","metadata":{"id":"MgdEwUGKMsBY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8HKXeOZTM4iC","colab_type":"text"},"source":["### Print the head of the new normalized DataFrame to make sure we did the operation correctly\n","\n","We want the values to be in the range of -10 and +10"]},{"cell_type":"code","metadata":{"id":"41uQz5JMM9xp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pS87acL4SCyk"},"source":["### Let us combine the lifestyle columns (series) together to reduce noise in the dataset\n","\n","We will do this by creating a new column in the original `df` DataFrame called `lifestyle_avg`. We will populate this new feature by taking the mean of the `normalized_lifestyle_df` column wise for each row.\n","\n","```python \n","df['lifestyle_avg'] = normalized_lifestyle_df[lifestyles].mean(axis=1)\n","```\n","\n","Note: we specify `axis=1` as the argument for the mean method to state taking the mean row wise.\n","\n","### Create a `lifestyle_avg` feature in the original `df`"]},{"cell_type":"code","metadata":{"id":"64mXQmWOOdVb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"skrFC5ZMTjUO","colab_type":"text"},"source":["### Drop the lifestyle features\n","\n","#### Pandas DataFrame drop() method parameters:\n","- `labels` (single label string or integer or a list of strings and integers): Index or column labels to drop.\n","- `axis` : {0 or ‘index/row’, 1 or ‘columns’}, default 0\n","Whether to drop labels from the index (0 or ‘index/row’) or columns (1 or ‘columns’). \n","- `inplace` (bool): default False; If True, do operation inplace and return None.\n","\n","**Note**:\n","Make sure to use the value `1` as the argument for the axis parameter"]},{"cell_type":"code","metadata":{"id":"ejXSFgtzTfn7","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z2fU23FvW8bJ","colab_type":"text"},"source":["### Display the head to make sure we have done the operation correctly."]},{"cell_type":"code","metadata":{"id":"OikBNtVyXG_4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"paH6zdiSYkHE","colab_type":"text"},"source":["<hr> \n","\n","### More Feature Engineering \n","\n","You can often engineer informative features by tapping into your (or others) expertise about the domain"]},{"cell_type":"markdown","metadata":{"id":"qHaUbr1tmZNn","colab_type":"text"},"source":["### Create an indicator variable to flag properties with 3 beds and 2 baths and name it `'three_and_two'`"]},{"cell_type":"code","metadata":{"id":"O0JgUS41mC50","colab_type":"code","colab":{}},"source":["# Create indicator variable for properties with 2 beds and 2 baths\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CQ3GJpgtjKUF","colab_type":"text"},"source":["### Create your own feature on the `df` DataFrame"]},{"cell_type":"code","metadata":{"id":"VIh_ZRFVjN6R","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gPLJYSYRljOO","colab_type":"text"},"source":["<hr> \n","\n","<br id=\"dummy\">\n","\n","## Encode dummy variables\n","\n","Python machine learning algorithms cannot handle categorical features directly. We will have to convert categorical variable into dummy/indicator variables, or variables that hold numerical values that represents categorical data in order for the computer to learn from these features. \n","\n","One-hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\n","\n","Technically, dummy variables are dichotomous, quantitative variables. Their range of values is small; they typically take on only two quantitative values, though sometimes can have more but the range should not have too many unique values. \n","\n","<br>\n","\n","### Let's create a new dataframe with dummy variables for our categorical features"]},{"cell_type":"markdown","metadata":{"id":"3wHWgtucljOQ","colab_type":"text"},"source":["#### Pandas `get_dummies()` method parameters:\n","- `data` (array-like, Series, or DataFrame): Data of which to get dummy indicators.\n","- `columns` (string, or list of strings): default None; Column names in the DataFrame to be encoded.\n","\n","#### pd.get_dummies() returns: \n","- The one-hot encoded version of the `df` you passed in\n","\n","**Note:** The new column names will be the old column name prepended before the categorical value name, seperated by underscores \n","\n","In order for the DataFrame to be updated with the one hot encoded columns we will have to reassign the original DataFrame with the return of the DataFrame's `get_dummies()` method.\n","\n","For Example: \n","```python\n","df = pd.get_dummies(data=df, columns=cols_to_encode)\n","```"]},{"cell_type":"markdown","metadata":{"id":"7JqR7GHtljOS","colab_type":"text"},"source":["#### **Make a list with the names of the columns that you want to encode. We will choose all of the categorical columns.**\n","\n","Let us encode the following categorical columns (series):\n","- exterior_walls\n","- roof\n","- property_type\n","\n","### Create a list variable `cols_to_encode` with the column names"]},{"cell_type":"code","metadata":{"id":"0WTptVJpljOT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6OEWBfErljOV","colab_type":"text"},"source":["**Here's a more generic approach, in case your dataframe has 40 categorical columns and you would rather have python populate the list for you.**\n","\n","```python \n","generic_list = df.dtypes[df.dtypes == \"object\"].index\n","```"]},{"cell_type":"markdown","metadata":{"id":"la0F2N8KljOZ","colab_type":"text"},"source":["### Using `pd.get_dummies()` encode the specified columns (series) from the original DataFrame \n","\n","#### Pandas get_dummies() method parameters:\n","- `data` (array-like, Series, or DataFrame): Data of which to get dummy indicators.\n","- `columns` (string, or list of strings): default None; Column names in the DataFrame to be encoded."]},{"cell_type":"code","metadata":{"id":"Do_LgV5QljOa","colab_type":"code","colab":{}},"source":["# Create new dataframe with dummy features\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwfy3P2SljOd","colab_type":"text"},"source":["#### Display the first 5 rows of your dataframe to see these new features."]},{"cell_type":"code","metadata":{"id":"jmeR0NCbljOf","colab_type":"code","colab":{}},"source":["# First 5 rows of dataframe\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ib5Qul3PljOm","colab_type":"text"},"source":["<div style=\"text-align:center; margin: 40px 0 40px 0;\">\n","    \n","[**Back to Contents**](#toc)\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"4YHLDEVCljOq","colab_type":"text"},"source":["<hr> \n","\n","<br id=\"remove\">\n","\n","## Remove unused or redundant features"]},{"cell_type":"markdown","metadata":{"id":"9SD1dZ4NljOr","colab_type":"text"},"source":["**Finally, let's save the target variable and drop unused -or- redundant features from our dataset.**"]},{"cell_type":"markdown","metadata":{"id":"Ax0T21sBljOt","colab_type":"text"},"source":["**Save <code style=\"color:steelblue\">'tx_year'</code> from your dataset, into the variable `target`.**"]},{"cell_type":"code","metadata":{"id":"tnOF7VKuljOu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ssVSB_sUmNI5"},"source":["<br>"]},{"cell_type":"markdown","metadata":{"id":"n2ymIUCaljO0","colab_type":"text"},"source":["**Drop <code style=\"color:steelblue\">'tx_price'</code> from your dataset.**\n","\n","We will do this with using the DataFrame's `.drop()` method.\n","\n","##### DataFrame's `drop()` parameters:\n","- `labels` (string or list of strings): index or column labels to drop\n","- `axis`  ({0 or ‘index’, 1 or ‘columns’}): default 0; whether to drop labels from the index (0 or ‘index’) or columns (1 or ‘columns’)\n","- `inplace` (bool): default False; If True, do operation inplace and return None.\n","\n"]},{"cell_type":"code","metadata":{"id":"R-TM2eiOljO1","colab_type":"code","colab":{}},"source":["# Drop 'tx_price' from the dataset\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bkXxamdRljO4","colab_type":"text"},"source":["<br>\n","\n","### Display the head to make sure we have the desired output"]},{"cell_type":"code","metadata":{"id":"O46PA80ZlaW5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"FrRQS2wgljO5","colab_type":"text"},"source":["<hr>\n","\n","# Save the analytical base table and target!\n","\n","Let's save the new dataframe using Pandas' <code style=\"color:steelblue\">.to_csv()</code> function\n","- Pass in the value None as an argument to the `index` parameter, so that Pandas drops the indices and only stores the actual data in the CSV.\n","\n","#### DataFrame's `to_csv()` Method Parameters:\n","- `path_or_buf` (string): File path of where to store DataFrame, if None is provided the result is returned as a string\n","- `index` (boolean or None): default True, Write row names (index).\n"]},{"cell_type":"markdown","metadata":{"id":"C8z4vyw3yUV7","colab_type":"text"},"source":["### Save The Analytical Base DataFrame\n","- use the following argument value for the `path_or_buf` parameter:\n","```python\n","path_or_buf='./cleaned_and_feature_engineered_real_estate.csv'\n","```\n"]},{"cell_type":"code","metadata":{"id":"-PdeK0S5ljO7","colab_type":"code","colab":{}},"source":["# Save analytical base table\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ld9Sm7MQyZhx","colab_type":"text"},"source":["### Save The Target Variable DataFrame\n","- use the following argument value for the `path_or_buf` parameter:\n","```python\n","path_or_buf='./cleaned_and_feature_engineered_real_estate.csv'\n","```"]},{"cell_type":"code","metadata":{"id":"NlyjvbwAljO-","colab_type":"code","colab":{}},"source":["# Save Target\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wSNaTIFnljPA","colab_type":"text"},"source":["<br>"]}]}